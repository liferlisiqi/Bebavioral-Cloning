{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D, Dropout\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Reload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reload:  ./pre-data.pickle\n",
      "X_train shape:  (24108, 80, 80, 3) y_train shape:  (24108,)\n"
     ]
    }
   ],
   "source": [
    "def reload_data(pickle_file):\n",
    "    print('reload: ', pickle_file)\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        pickle_data = pickle.load(f)\n",
    "        X_train = pickle_data['X_train']\n",
    "        y_train = pickle_data['y_train']\n",
    "        del pickle_data  # Free up memory\n",
    "    return X_train, y_train\n",
    "\n",
    "X_train, y_train = reload_data('./pre-data.pickle')\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "print('X_train shape: ', X_train.shape, 'y_train shape: ',y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvidia = Sequential()\n",
    "nvidia.add(Lambda(lambda x: x/255. - 0.5, input_shape=(80, 80, 3)))\n",
    "nvidia.add(Cropping2D(cropping=((35, 13), (0, 0))))\n",
    "nvidia.add(Convolution2D(24, 3, 3, subsample=(2, 2), activation='relu'))\n",
    "nvidia.add(Convolution2D(36, 3, 3, subsample=(2, 2), activation='relu'))\n",
    "nvidia.add(Convolution2D(48, 3, 3, activation='relu'))\n",
    "nvidia.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "nvidia.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "nvidia.add(Dropout(0.5))\n",
    "nvidia.add(Flatten())\n",
    "nvidia.add(Dense(100))\n",
    "nvidia.add(Dense(50))\n",
    "nvidia.add(Dense(10))\n",
    "nvidia.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19286 samples, validate on 4822 samples\n",
      "Epoch 1/5\n",
      "19286/19286 [==============================] - 130s - loss: 0.0131 - val_loss: 0.0111\n",
      "Epoch 2/5\n",
      "19286/19286 [==============================] - 10s - loss: 0.0110 - val_loss: 0.0108\n",
      "Epoch 3/5\n",
      "19286/19286 [==============================] - 12s - loss: 0.0105 - val_loss: 0.0104\n",
      "Epoch 4/5\n",
      "19286/19286 [==============================] - 12s - loss: 0.0102 - val_loss: 0.0100\n",
      "Epoch 5/5\n",
      "19286/19286 [==============================] - 12s - loss: 0.0099 - val_loss: 0.0102\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Hyperparameters\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 5\n",
    "\n",
    "# Training\n",
    "nvidia.compile(loss='mse', optimizer=Adam(LEARNING_RATE))\n",
    "nvidia.fit(X_train, y_train, validation_split=0.2, \n",
    "           shuffle=True, nb_epoch=EPOCHS)\n",
    "nvidia.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Train the model with generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8036\n",
      "6428 1608\n"
     ]
    }
   ],
   "source": [
    "lines = []\n",
    "with open('./sample_data/data/driving_log.csv') as sample_file:\n",
    "    sample_file.readline()\n",
    "    reader = csv.reader(sample_file)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "print(len(lines))\n",
    "\n",
    "train_lines, valid_lines = train_test_split(lines, test_size=0.2, random_state=1)\n",
    "print(len(train_lines), len(valid_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "def generator(samples, batch_size):\n",
    "    ns = len(samples)\n",
    "    while True:\n",
    "        indices = np.random.randint(0, ns, batch_size)\n",
    "#         batch_samples = samples[indices]\n",
    "#         print(batch_samples)\n",
    "        images = []\n",
    "        angles = []\n",
    "        for indix in indices:\n",
    "            sample = samples[indix]\n",
    "            center_path = './sample_data/data/IMG/' + sample[0].split('/')[-1]\n",
    "            center_img = plt.imread(center_path)\n",
    "            center_img = cv2.resize(center_img, (80,80))\n",
    "            center_angle = float(line[3])\n",
    "            images.append(center_img)\n",
    "            angles.append(center_angle)\n",
    "\n",
    "            left_path = './sample_data/data/IMG/' + sample[1].split('/')[-1]\n",
    "            left_img = plt.imread(left_path)\n",
    "            left_img = cv2.resize(left_img, (80,80))\n",
    "            left_angle = float(line[3]) + 0.10\n",
    "            images.append(left_img)\n",
    "            angles.append(left_angle)\n",
    "\n",
    "            right_path = './sample_data/data/IMG/' + sample[2].split('/')[-1]\n",
    "            right_img = plt.imread(right_path)\n",
    "            right_img = cv2.resize(right_img, (80,80))\n",
    "            right_angle = float(line[3]) - 0.10\n",
    "            images.append(right_img)\n",
    "            angles.append(right_angle)\n",
    "\n",
    "        yield np.array(images), np.array(angles)\n",
    "            \n",
    "train_generator = generator(train_lines, BATCH_SIZE)\n",
    "valid_generator = generator(valid_lines, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "38400/38400 [==============================] - 53s - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 2/5\n",
      "38400/38400 [==============================] - 48s - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 3/5\n",
      "38400/38400 [==============================] - 48s - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 4/5\n",
      "38400/38400 [==============================] - 49s - loss: 0.0010 - val_loss: 0.0020\n",
      "Epoch 5/5\n",
      "38400/38400 [==============================] - 49s - loss: 9.5612e-04 - val_loss: 0.0020\n",
      "CPU times: user 5min 1s, sys: 13.3 s, total: 5min 15s\n",
      "Wall time: 4min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Hyperparameters\n",
    "LEARNING_RATE = 5e-4\n",
    "EPOCHS = 5\n",
    "SAMPLES_PER_EPOCH = 6*BATCH_SIZE*int(len(train_lines)/BATCH_SIZE)\n",
    "NB_VAL_SAMPLES = 3*BATCH_SIZE*int(len(valid_lines)/BATCH_SIZE)\n",
    "\n",
    "# Training\n",
    "nvidia.compile(loss='mse', optimizer=Adam(LEARNING_RATE))\n",
    "nvidia.fit_generator(train_generator, \n",
    "                     samples_per_epoch=SAMPLES_PER_EPOCH,\n",
    "                     validation_data=valid_generator, \n",
    "                     nb_val_samples=NB_VAL_SAMPLES, \n",
    "                     nb_epoch=EPOCHS, verbose=1)\n",
    "nvidia.save('modelg.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
